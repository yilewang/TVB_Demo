{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An illustration of personal meeting with Dr. Solodkin at Jan 03\n",
    "\n",
    "1. generate the graph, ggdist\n",
    "2. use script to calculate the meta-connectivity of cluster 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n@Author: Yile Wang\\n\\nThis script is used to calculate the homotopic meta-connectivity in four groups, SNC, NC, MCI, AD\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from turtle import color\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/home/yat-lok/workspace/Network-science-Toolbox/Python')\n",
    "# sys.path.append('/home/wayne/github/TVB_workflow/new_g_optimal')\n",
    "# sys.path.append('/home/wayne/github/Network-science-Toolbox/Python')\n",
    "from TS2dFCstream import TS2dFCstream\n",
    "from dFCstream2Trimers import dFCstream2Trimers\n",
    "from dFCstream2MC import dFCstream2MC\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats.stats import pearsonr\n",
    "import itertools\n",
    "import os\n",
    "import scipy.io\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "@Author: Yile Wang\n",
    "\n",
    "This script is used to calculate the homotopic meta-connectivity in four groups, SNC, NC, MCI, AD\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5   6   7   8   9  10  11  12  13  14  19  20  21  22  23  24  25  26\n",
      "  27  28  32  33  34  35  36  37  38  39  40  41  44  45  46  47  48  49\n",
      "  50  51  52  53  55  56  57  58  59  60  61  62  63  64  65  66  67  68\n",
      "  69  70  71  72  73  74   0   1   2   3   4  15  16  17  18  29  30  31\n",
      "  42  43  54  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n"
     ]
    }
   ],
   "source": [
    "# brain region labels for your reference\n",
    "regions = ['aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "regionswithgroups = ['groups','aCNG-L', 'aCNG-R','mCNG-L','mCNG-R','pCNG-L','pCNG-R', 'HIP-L','HIP-R','PHG-L','PHG-R','AMY-L','AMY-R', 'sTEMp-L','sTEMP-R','mTEMp-L','mTEMp-R']\n",
    "group = ['SNC', 'NC', 'MCI','AD']\n",
    "\n",
    "regions14 = []\n",
    "for i in range(14):\n",
    "    wt = [\"regions_\", str(i)]\n",
    "    wt = \"\".join(wt)\n",
    "    regions14.append(wt)\n",
    "\n",
    "djouya_index = scipy.io.loadmat('/home/yat-lok/workspace/data4project/lateralization/gc1sec_res/meta/idx.mat')\n",
    "mc_index = djouya_index['idx'].T[0] -1\n",
    "\n",
    "path = '/home/yat-lok/workspace/data4project/lateralization/tvb_parameters.xlsx'\n",
    "coData = pd.read_excel(path, index_col=0)\n",
    "print(mc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      "  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      "  126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      "  144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      "  162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      "  180 181 182 183 184 185 186 187 188 189]]\n"
     ]
    }
   ],
   "source": [
    "# iterate simulated functional connectivity\n",
    "if __name__ == \"__main__\":\n",
    "    tmp_col = [\"group\", \"caseid\"]\n",
    "    pcng_vector = np.array([[*range(190)]])\n",
    "    for grp in group:\n",
    "        # subject case ids\n",
    "        ldir = os.listdir(\"/home/yat-lok/workspace/data4project/lateralization/ts_fmri/\"+ grp+'-TS')\n",
    "        # ldir = os.listdir('/home/wayne/TS-4-Vik/'+grp+'-TS/')\n",
    "        \n",
    "        for ind, y in enumerate(ldir):\n",
    "            # import empirical functional connectivity\n",
    "            # Here is the path of the mat file of the FC data\n",
    "            pth_efc = \"/home/yat-lok/workspace/data4project/lateralization/ts_fmri/\"+ grp+'-TS/'+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "            # pth_efc = \"/home/wayne/TS-4-Vik/\"+grp+\"-TS/\"+ y +\"/ROISignals_\"+ y +\".mat\"\n",
    "            ea = scipy.io.loadmat(pth_efc)\n",
    "            all = ea['ROISignals']\n",
    "            df = pd.DataFrame.from_dict(all)\n",
    "            df.columns = regions\n",
    "            # calculate the meta-connectivity, using existing script:\n",
    "            dFCstream = TS2dFCstream(df.to_numpy(), 5, None, '2D')\n",
    "            # Calculate MC\n",
    "            MC_MC = dFCstream2MC(dFCstream)\n",
    "            # sort the matrix\n",
    "            mc = np.zeros((len(mc_index),len(mc_index)))\n",
    "            for mc_row in range(len(mc_index)-1):\n",
    "                for mc_col in range(mc_row+1,len(mc_index)):\n",
    "                    mc[mc_row, mc_col] = MC_MC[mc_index[mc_row], mc_index[mc_col]]\n",
    "            mc_sorted_cluster3 = mc + mc.T\n",
    "            mc_cluster3 = mc_sorted_cluster3[40:60, 40:60]\n",
    "            tmp_mc = np.tril(mc_cluster3,k=0).flatten()\n",
    "            tmp_cluster3 = np.array([[y for y in tmp_mc if y != 0.0]])\n",
    "            pcng_vector = np.concatenate((pcng_vector, tmp_cluster3), axis = 0)\n",
    "    pd.DataFrame(pcng_vector).to_excel(\"../../data4project/lateralization/gc1sec_res/meta/mc_cluster3.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvbenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d6eff59d82162ad618c2fda16bbe4a2b1e156e75fbd6961cfe85de3ca5351f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
