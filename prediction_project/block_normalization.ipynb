{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabs_names = ['Ignition', 'TVB1', 'TVB2', 'TVB3', 'TVB4', 'SC', 'WDC']\n",
    "tabs_names = ['mean_Ignition', 'TVB1', 'TVB2', 'TVB3', 'TVB4', 'SC', 'WDC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization method 1: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to /Users/yilewang/workspaces/data4project/prediction_project/block_normalized_pca.xlsx\n"
     ]
    }
   ],
   "source": [
    "output_file = '/Users/yilewang/workspaces/data4project/prediction_project/block_normalized_pca.xlsx'\n",
    "# with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "#     for tab_name in tabs_names:\n",
    "#         tab = pd.read_excel('/Users/yilewang/workspaces/data4project/prediction_project/block_normalization.xlsx', sheet_name=tab_name, skiprows=1)\n",
    "#         # do PCA\n",
    "#         scaler = StandardScaler()\n",
    "#         scaled_data = scaler.fit_transform(tab.iloc[:, 3:])\n",
    "#         pca = PCA(n_components=1)\n",
    "#         pca_result = pca.fit_transform(scaled_data)\n",
    "#         # square root of the first principal component\n",
    "\n",
    "#         # Square root of the first principal component scores\n",
    "#         pca_first_component_scores = pca_result[:, 0]\n",
    "#         pca_sqrt = np.sqrt(np.abs(pca_first_component_scores)).reshape(-1, 1)\n",
    "        \n",
    "#         # Normalize the tab using the square root of the first principal component\n",
    "#         tab_sqrt = tab.iloc[:, 3:].div(pca_sqrt, axis=0)\n",
    "#         # add the first three columns to the new tab\n",
    "#         tab_sqrt.insert(0, 'group', tab['group'])\n",
    "#         tab_sqrt.insert(1, 'caseid', tab['caseid'])\n",
    "#         # write the result to each tab in a new file\n",
    "#         tab_sqrt.to_excel(writer, sheet_name=tab_name, index=False)\n",
    "# print(f\"Data written to {output_file}\")\n",
    "\n",
    "# Open an Excel writer\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    for tab_name in tabs_names:\n",
    "        # Read the data from each sheet, skipping the first row\n",
    "        tab = pd.read_excel('/Users/yilewang/workspaces/data4project/prediction_project/block_normalization.xlsx', sheet_name=tab_name, skiprows=1)\n",
    "        \n",
    "        # Select the data columns (assuming the first three columns are not data)\n",
    "        data_columns = tab.columns[3:]\n",
    "        \n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(tab[data_columns])\n",
    "        \n",
    "        # Perform PCA to get the first principal component\n",
    "        pca = PCA(n_components=1)\n",
    "        pca.fit(scaled_data)\n",
    "        \n",
    "        # Get the first eigenvalue\n",
    "        eigenvalue = pca.explained_variance_[0]\n",
    "        \n",
    "        # Take the square root of the first eigenvalue\n",
    "        sqrt_eigenvalue = np.sqrt(eigenvalue)\n",
    "        \n",
    "        # Normalize the original data by dividing by the square root of the first eigenvalue\n",
    "        normalized_data = tab[data_columns].div(sqrt_eigenvalue)\n",
    "        # add the first three columns to the new tab\n",
    "        normalized_data.insert(0, 'group', tab['group'])\n",
    "        normalized_data.insert(1, 'caseid', tab['caseid'])\n",
    "        # Write the result to each sheet in a new file\n",
    "        normalized_data.to_excel(writer, sheet_name=tab_name, index=False)\n",
    "\n",
    "print(f\"Data written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Normalizartion method 1 to wave2 WMH data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_PCA_first_eigenvalues(tab):\n",
    "    # Select the data columns (assuming the first three columns are not data)\n",
    "    data_columns = tab.columns[5:23]\n",
    "    \n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(tab[data_columns])\n",
    "    \n",
    "    # Perform PCA to get the first principal component\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(scaled_data)\n",
    "    \n",
    "    # Get the first eigenvalue\n",
    "    eigenvalue = pca.explained_variance_[0]\n",
    "    \n",
    "    # Take the square root of the first eigenvalue\n",
    "    sqrt_eigenvalue = np.sqrt(eigenvalue)\n",
    "    \n",
    "    # Normalize the original data by dividing by the square root of the first eigenvalue\n",
    "    normalized_data = tab[data_columns].div(sqrt_eigenvalue)\n",
    "    # add the first three columns to the new tab\n",
    "    normalized_data.insert(0, 'group', tab['M_w2_group'])\n",
    "    normalized_data.insert(1, 'caseid', tab['M_w2_ID'])\n",
    "    return normalized_data\n",
    "\n",
    "wave2_wmh = pd.read_excel('/Users/yilewang/workspaces/data4project/MAS_T2w/waves_wmh.xlsx', sheet_name='wave2')\n",
    "wave2_wmh = wave2_wmh.dropna()\n",
    "wave2_wmh_normalized = normalize_PCA_first_eigenvalues(wave2_wmh)\n",
    "wave2_wmh_normalized.to_excel('/Users/yilewang/workspaces/data4project/prediction_project/waves2_wmh_normalized.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization method 2: Sum of Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sum_squares(tab):\n",
    "    \"\"\"\n",
    "    Normalize each column in the DataFrame by calculating the sum of squares for each column,\n",
    "    then dividing each value in the column by the square root of this sum.\n",
    "\n",
    "    Args:\n",
    "    tab (pd.DataFrame): The input data table with variables to be normalized.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The normalized data table.\n",
    "    \"\"\"\n",
    "    # Initialize an empty DataFrame to store normalized data\n",
    "    normalized_tab = pd.DataFrame()\n",
    "\n",
    "    for column in tab.columns[3:]:\n",
    "        # Calculate the sum of squares for the current column\n",
    "        sum_of_squares = np.sum(np.square(tab[column]))\n",
    "        \n",
    "        # Calculate the normalization factor (square root of the sum of squares)\n",
    "        normalization_factor = np.sqrt(sum_of_squares)\n",
    "        \n",
    "        # Normalize the current column\n",
    "        normalized_tab[column] = tab[column] / normalization_factor\n",
    "\n",
    "    return normalized_tab\n",
    "\n",
    "tab = pd.read_excel('/Users/yilewang/workspaces/data4project/prediction_project/block_normalization.xlsx', sheet_name='All', skiprows=1)\n",
    "\n",
    "# Normalize the data using the sum of squares method\n",
    "normalized_tab = normalize_sum_squares(tab)\n",
    "\n",
    "# Add the first three columns to the normalized data table\n",
    "normalized_tab.insert(0, 'group', tab['group'])\n",
    "normalized_tab.insert(1, 'caseid', tab['caseid'])\n",
    "\n",
    "# Write the normalized data table to a new Excel file\n",
    "output_file = '/Users/yilewang/workspaces/data4project/prediction_project/block_normalized_sumsquares.xlsx'\n",
    "normalized_tab.to_excel(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization method 3: sqrt of N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_N(tab):\n",
    "    # get the number of samples\n",
    "    N = sum(tab.groupby('group').size())\n",
    "    \n",
    "    # Create a copy of the dataframe to avoid modifying the original one\n",
    "    normalized_tab = tab.copy()\n",
    "    \n",
    "    # Iterate over the columns to normalize (assuming columns from index 3 onwards need normalization)\n",
    "    # for col in tab.columns[3:]:\n",
    "    #     for group in N.index:\n",
    "    #         mask = tab['group'] == group\n",
    "    #         sqrt_N = np.sqrt(N[group])\n",
    "    #         normalized_tab.loc[mask, col] = tab.loc[mask, col] / sqrt_N\n",
    "    normalized_tab.iloc[:, 3:] = tab.iloc[:, 3:].div(np.sqrt(N), axis=0)\n",
    "    \n",
    "    return normalized_tab\n",
    "\n",
    "# Load the data\n",
    "tab = pd.read_excel('/Users/yilewang/workspaces/data4project/prediction_project/block_normalization.xlsx', sheet_name='All', skiprows=1)\n",
    "\n",
    "# Normalize the data\n",
    "normalized_tab = normalize_N(tab)\n",
    "\n",
    "# Save the normalized data to a new Excel file if needed\n",
    "normalized_tab.to_excel('/Users/yilewang/workspaces/data4project/prediction_project/normalized_N.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvbenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
